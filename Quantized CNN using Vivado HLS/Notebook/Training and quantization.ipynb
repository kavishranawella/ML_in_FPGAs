{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of training_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Training a 8-bit Quantized CNN for MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjmi3qZeu_xk"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The model is trained using Keras and is quantized to a TFLite model. Then the necessary parameters are extracted from the TFLite model to be used in HLS code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEAZYXvZU_XG"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN4yVFK5-0Bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dfd9459-2876-4551-9fc3-9c6cadf973a6"
      },
      "source": [
        "! pip uninstall -y tensorflow\n",
        "! pip install -q tf-nightly\n",
        "! pip install -q tensorflow-model-optimization\n",
        "! pip install h5py\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.1:\n",
            "  Successfully uninstalled tensorflow-2.4.1\n",
            "\u001b[K     |████████████████████████████████| 408.3MB 43kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0MB 54.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9MB 25.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 471kB 44.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0MB 44.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 44.9MB/s \n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 174kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.12; python_version == \"3.6\" in /usr/local/lib/python3.6/dist-packages (from h5py) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frVmHpGZs30D",
        "outputId": "16a5e8b8-0baa-4f29-806c-c5580e26aa49"
      },
      "source": [
        "#Step 2: Mount your google drive (OPTIONAL)\n",
        "###########################################\n",
        "\n",
        "#Mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKTmdKL74kIt",
        "outputId": "bb1e810d-3132-4779-d382-7ddc23a8c4d9"
      },
      "source": [
        "%cd gdrive/My Drive/Test2/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Test2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJwIonXEVJo6"
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTsADunCZ0OI",
        "outputId": "fbb85266-1d2f-41f4-e726-d95a23446969"
      },
      "source": [
        "#os.chdir('/content/gdrive/My Drive/Test')\n",
        "#os.environ['PATH'] = '/content/gdrive/My Drive/Test' + ';' + os.environ['PATH']\n",
        "#print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psViY5PRDurp"
      },
      "source": [
        "## Train a model for MNIST without quantization aware training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbY-KGMPvbW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c3b1108-e6ac-4c29-daf2-60b17099af29"
      },
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
        "\n",
        "test_images = np.pad(test_images, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "train_images = np.pad(train_images, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "#train_images = train_images / 255.0\n",
        "#test_images = test_images / 255.0\n",
        "\n",
        "# Define the model architecture.\n",
        "model = keras.Sequential([\n",
        "  #keras.layers.InputLayer(input_shape=(32, 32)),\n",
        "  #keras.layers.Reshape(target_shape=(32, 32, 1)),\n",
        "  keras.layers.Conv2D(filters=8, kernel_size=(4, 4), input_shape=(32, 32, 1), activation='relu'),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "  keras.layers.Conv2D(filters=16, kernel_size=(2, 2), activation='relu'),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(120, activation='relu'),\n",
        "  keras.layers.Dense(84, activation='relu'),\n",
        "  keras.layers.Dense(10, activation=None)\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=1,\n",
        "  validation_split=0.1,\n",
        ")\n",
        "model.summary()\n",
        "weights1=model.get_weights()\n",
        "with open('./output/normal.txt', 'w') as f1:\n",
        "  print(weights1, file=f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1688/1688 [==============================] - 22s 13ms/step - loss: 1.7735 - accuracy: 0.8416 - val_loss: 0.0985 - val_accuracy: 0.9707\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 29, 29, 8)         136       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 16)        528       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 120)               69240     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 80,918\n",
            "Trainable params: 80,918\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNY8L1GxHkL4",
        "outputId": "d893aa0a-2ae7-44bb-cc6b-541fab8b2ac3"
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/gdrive/MyDrive/Test2/model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/content/gdrive/MyDrive/Test2/model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8747K9OE72P"
      },
      "source": [
        "## Clone and fine-tune pre-trained model with quantization aware training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F19k7ExXF_h2"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsZROpNYMWQ0"
      },
      "source": [
        "You will apply quantization aware training to the whole model and see this in the model summary. All layers are now prefixed by \"quant\".\n",
        "\n",
        "Note that the resulting model is quantization aware but not quantized (e.g. the weights are float32 instead of int8). The sections after show how to create a quantized model from the quantization aware one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq6blGjgFDCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431638f9-acd7-40ef-8794-8512bd67be39"
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "# q_aware stands for for quantization aware.\n",
        "q_aware_model = quantize_model(model)\n",
        "\n",
        "# `quantize_model` requires a recompile.\n",
        "q_aware_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "q_aware_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "quantize_layer (QuantizeLaye (None, 32, 32, 1)         3         \n",
            "_________________________________________________________________\n",
            "quant_conv2d_2 (QuantizeWrap (None, 29, 29, 8)         155       \n",
            "_________________________________________________________________\n",
            "quant_max_pooling2d_2 (Quant (None, 14, 14, 8)         1         \n",
            "_________________________________________________________________\n",
            "quant_conv2d_3 (QuantizeWrap (None, 13, 13, 16)        563       \n",
            "_________________________________________________________________\n",
            "quant_max_pooling2d_3 (Quant (None, 6, 6, 16)          1         \n",
            "_________________________________________________________________\n",
            "quant_flatten_1 (QuantizeWra (None, 576)               1         \n",
            "_________________________________________________________________\n",
            "quant_dense_3 (QuantizeWrapp (None, 120)               69245     \n",
            "_________________________________________________________________\n",
            "quant_dense_4 (QuantizeWrapp (None, 84)                10169     \n",
            "_________________________________________________________________\n",
            "quant_dense_5 (QuantizeWrapp (None, 10)                855       \n",
            "=================================================================\n",
            "Total params: 80,993\n",
            "Trainable params: 80,918\n",
            "Non-trainable params: 75\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDr2ijwpGCI-"
      },
      "source": [
        "### Train and evaluate the model against baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUBEn94hXYB1"
      },
      "source": [
        "To demonstrate fine tuning after training the model for just an epoch, fine tune with quantization aware training on a subset of the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PHDGJryE31X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a32a7bfb-cfd3-4ab8-a556-f9a17a08d3eb"
      },
      "source": [
        "train_images_subset = train_images[0:1000] # out of 60000\n",
        "train_labels_subset = train_labels[0:1000]\n",
        "\n",
        "q_aware_model.fit(train_images_subset, train_labels_subset,\n",
        "                  batch_size=500, epochs=1, validation_split=0.1)\n",
        "weights2=q_aware_model.get_weights()\n",
        "with open('./output/quantize_aware.txt', 'w') as f2:\n",
        "  print(weights2, file=f2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 206ms/step - loss: 0.3039 - accuracy: 0.9489 - val_loss: 0.3306 - val_accuracy: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-byC2lYlMkfN"
      },
      "source": [
        "For this example, there is minimal to no loss in test accuracy after quantization aware training, compared to the baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bMFTKSSHyyZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97972b0c-19ff-486c-a03e-d68062547ccf"
      },
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "_, q_aware_model_accuracy = q_aware_model.evaluate(\n",
        "   test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "print('Quant test accuracy:', q_aware_model_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline test accuracy: 0.9679999947547913\n",
            "Quant test accuracy: 0.9175999760627747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IepmUPSITn6"
      },
      "source": [
        "## Create quantized model for TFLite backend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FgNP4rbOLH8"
      },
      "source": [
        "After this, you have an actually quantized model with int8 weights and uint8 activations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7fztWsAOHTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "367e548e-c85b-4fb1-c2e8-01872325b5c8"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()\n",
        "#quantized_tflite_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_2_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn, max_pooling2d_2_layer_call_and_return_conditional_losses, max_pooling2d_2_layer_call_fn, conv2d_3_layer_call_and_return_conditional_losses while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmhh0kkp7/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpmhh0kkp7/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEYsyYVqNgeY"
      },
      "source": [
        "## See persistence of accuracy from TF to TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saadXD4JQsBK"
      },
      "source": [
        "Define a helper function to evaluate the TF Lite model on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8yBouuGNqls"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuEFS4CIQvUw"
      },
      "source": [
        "You evaluate the quantized model and see that the accuracy from TensorFlow persists to the TFLite backend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqQTyqz4NsWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6a8a24-eba9-433b-fde9-99ef8df046c4"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter)\n",
        "\n",
        "print('Quant TFLite test_accuracy:', test_accuracy)\n",
        "print('Quant TF test accuracy:', q_aware_model_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "Evaluated on 7000 results so far.\n",
            "Evaluated on 8000 results so far.\n",
            "Evaluated on 9000 results so far.\n",
            "\n",
            "\n",
            "Quant TFLite test_accuracy: 0.9172\n",
            "Quant TF test accuracy: 0.9175999760627747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8D7WnFF5DZR"
      },
      "source": [
        "## See 4x smaller model from quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1c2IecBRCdQ"
      },
      "source": [
        "You create a float TFLite model and then see that the quantized TFLite model\n",
        "is 4x smaller."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy_Lgfh8VkyX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "07dd93bc-3f03-4cd5-e397-9b528b60afde"
      },
      "source": [
        "path_name = '/content/gdrive/MyDrive/Test2/'\n",
        "# Create float TFLite model.\n",
        "float_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "float_tflite_model = float_converter.convert()\n",
        "\n",
        "# Measure sizes of models.\n",
        "_, float_file = tempfile.mkstemp('.tflite')\n",
        "_, quant_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open('/content/gdrive/MyDrive/Test2/quant_file', 'wb') as f:\n",
        "  f.write(quantized_tflite_model)\n",
        "\n",
        "with open('/content/gdrive/MyDrive/Test2/float_file', 'wb') as f:\n",
        "  f.write(float_tflite_model)\n",
        "\n",
        "print(\"Float model in Mb:\", os.path.getsize(float_file) / float(2**20))\n",
        "print(\"Quantized model in Mb:\", os.path.getsize(quant_file) / float(2**20))\n",
        "print(os.path.dirname(quant_file))\n",
        "%pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp4wkttv9z/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp4wkttv9z/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Float model in Mb: 0.0\n",
            "Quantized model in Mb: 0.0\n",
            "/tmp\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/Test2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JQ7g_ppI4-b"
      },
      "source": [
        "# get details for each layer\n",
        "all_layers_details = interpreter.get_tensor_details() \n",
        "\n",
        "\n",
        "f = h5py.File(\"mobilenet_v3_weights_infos.hdf5\", \"w\")   \n",
        "\n",
        "for layer in all_layers_details:\n",
        "     # to create a group in an hdf5 file\n",
        "     grp = f.create_group(str(layer['index']))\n",
        "\n",
        "     # to store layer's metadata in group's metadata\n",
        "     grp.attrs[\"name\"] = layer['name']\n",
        "     grp.attrs[\"shape\"] = layer['shape']\n",
        "     # grp.attrs[\"dtype\"] = all_layers_details[i]['dtype']\n",
        "     grp.attrs[\"quantization\"] = layer['quantization']\n",
        "\n",
        "     # to store the weights in a dataset\n",
        "     grp.create_dataset(\"weights\", data=interpreter.get_tensor(layer['index']))\n",
        "\n",
        "\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlllA6DzvbCJ"
      },
      "source": [
        "def save_W1(W1,name):\n",
        "    W1_numpy = np.empty((0), dtype = float)\n",
        "    for i in W1:    \n",
        "        #aux = W1[: , : , :1 , i:i+1]\n",
        "        #aux = np.reshape(aux,(4,4))\n",
        "        W1_numpy = np.append(W1_numpy,i)\n",
        "    np.savetxt('./output/'+name+'.out',W1_numpy, delimiter=',') \n",
        "\n",
        "with open('./output/quantized.txt', 'w') as f3:\n",
        "  for layer in all_layers_details:\n",
        "      # to create a group in an hdf5 file\n",
        "      print('----------------------------------------------------------------------------------------------------------------', file=f3)\n",
        "      print(str(layer['index'])+' - '+str(layer['name']), file=f3)\n",
        "      dim=int(layer['shape'].size)\n",
        "      if (dim):\n",
        "        print('Dimensions = '+str(layer['shape']), file=f3)\n",
        "        save_W1(interpreter.get_tensor(layer['index']),str(layer['index']))\n",
        "      print ('\\n Quantizations:', file=f3)\n",
        "      print (layer['quantization'], file=f3)\n",
        "      print ('\\n Scales:', file=f3)\n",
        "      print (layer['quantization_parameters']['scales'], file=f3)\n",
        "      print ('\\n Zero points:', file=f3)\n",
        "      print (layer['quantization_parameters']['zero_points'], file=f3)\n",
        "      print ('\\n Quantized dimensions:', file=f3)\n",
        "      print (layer['quantization_parameters']['quantized_dimension'], file=f3)\n",
        "      print ('\\n Tensors:', file=f3)\n",
        "      temp=list(interpreter.get_tensor(layer['index']))\n",
        "      a=len(temp)\n",
        "      if (dim==2):\n",
        "        print('{', file=f3)\n",
        "        for i in range(a):\n",
        "          print('{',end='', file=f3)\n",
        "          print(','.join(str(x) for x in temp[i]),end='', file=f3)\n",
        "          if i == a-1:\n",
        "            print('}', file=f3, end='')\n",
        "          else:\n",
        "            print('},', file=f3)\n",
        "        print('};', file=f3)\n",
        "      elif (dim==4):\n",
        "        #print('{', file=f3)\n",
        "        for i in range(a):\n",
        "          b=len(temp[i])\n",
        "          print('{', end='',file=f3)\n",
        "          for j in range(b):\n",
        "            print('{', end='',file=f3)\n",
        "            c=len(temp[i][j])\n",
        "            for k in range(c):\n",
        "              if (list(layer['shape'])[3]==1):\n",
        "                print('{', end='',file=f3)\n",
        "                print(','.join(str(x) for x in temp[i][j][k]),end='', file=f3)\n",
        "                if k==c-1:\n",
        "                  print('}',end='', file=f3)\n",
        "                else:\n",
        "                  print('},',end='', file=f3)\n",
        "              else:\n",
        "                print('{', end='',file=f3)\n",
        "                print(','.join(str(x) for x in temp[i][j][k]),end='', file=f3)\n",
        "                if k==c-1:\n",
        "                  print('}',end='', file=f3)\n",
        "                else:\n",
        "                  print('},', file=f3)\n",
        "            if j==b-1:\n",
        "              print('}', file=f3)\n",
        "            else:\n",
        "              print('},', file=f3)\n",
        "          if i==a-1:\n",
        "            print('};', file=f3)\n",
        "          else:\n",
        "            print('},', file=f3)\n",
        "        #print('};', file=f3)\n",
        "      else:\n",
        "        print(temp, file=f3)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxjRALSf3nbA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb269b1-814b-45ec-9d6c-e6be0d56df04"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def reference_io(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  with open('./output/refernce.txt', 'w') as f4:\n",
        "    for i, test_image in enumerate(test_images[0:10]):\n",
        "      # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "      # the model's input data format.\n",
        "      print(\"Image %i \\n \\n\" %i, file=f4)\n",
        "      print('Input before float: \\n', file=f4)\n",
        "      for line in test_image:\n",
        "        print(','.join(str(x[0]) for x in line), file=f4)\n",
        "      test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "      #print('\\n Input after float: \\n', file=f4)\n",
        "      #for line2 in test_image:\n",
        "        #for line in line2:\n",
        "          #print(','.join(str(x[0]) for x in line, file=f4)\n",
        "      interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "      # Run inference.\n",
        "      interpreter.invoke()\n",
        "\n",
        "      # Post-processing: remove batch dimension and find the digit with highest\n",
        "      # probability.\n",
        "      output = interpreter.tensor(output_index)\n",
        "      print('\\n Output: \\n', file=f4)\n",
        "      print(output()[0], file=f4)\n",
        "      digit = np.argmax(output()[0])\n",
        "      print('\\n Prediction: \\n', file=f4)\n",
        "      print(digit, file=f4)\n",
        "      print('\\n \\n \\n -------------------------------------------------------------------------------------------------- \\n \\n \\n', file=f4)\n",
        "\n",
        "    print('\\n', file=f4)\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  return\n",
        "\n",
        "reference_io(interpreter)\n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O5xuci-SonI"
      },
      "source": [
        "## Final Note"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2I7xmyMW5QY"
      },
      "source": [
        "The code can be further improved to create a file that can be directly used in HLS.\n"
      ]
    }
  ]
}